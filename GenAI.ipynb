{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yehawbfnDjgJ",
        "outputId": "e3e3071e-7ab2-4f7d-987a-14a9fe151d3e"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers torch  # Install necessary libraries\n",
        "\n",
        "from transformers import pipeline  # Import the pipeline function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lpUZbItEKS3",
        "outputId": "42ddf61e-432a-4e6b-aa5c-ddd121d5b6ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eb2c8eb5e634ffc8e087c378146b5cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\anaconda3\\envs\\dung\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dbda.STUDENTSDC\\.cache\\huggingface\\hub\\models--FacebookAI--xlm-roberta-large-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\anaconda3\\envs\\dung\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d1eae752c8d49ca819480a0d3e273f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc27887d4c9c459ba9a0b326d3108a3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "086a2212a4234e578212afeb42a5f1a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee8271fdf78a445c87282451231d9a9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ner = pipeline(\"token-classification\", model=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaLRC09iEpqS",
        "outputId": "70f22349-deb1-4054-cb9f-a4787aeedf9b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "819f7b090e524b1da10397e3dc288a76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\anaconda3\\envs\\dung\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dbda.STUDENTSDC\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7d3996754d4233a8971ded22bf7a4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "967f747c05a34cfdb672963fafd3c322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e43adf7d0c947cdb1893fa877db26f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0e13e65cca468ab8a268d54bf72691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84234508bd42425d97dcde3844bf369a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ner= pipeline(\"token-classification\", model=\"dslim/bert-base-NER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COnO7AhyFWqT",
        "outputId": "b1e1382b-468c-433c-ca4b-28607288eb06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.96848685,\n",
              "  'index': 1,\n",
              "  'word': 'Na',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.24457698,\n",
              "  'index': 2,\n",
              "  'word': '##ren',\n",
              "  'start': 2,\n",
              "  'end': 5},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.6211486,\n",
              "  'index': 3,\n",
              "  'word': '##dra',\n",
              "  'start': 5,\n",
              "  'end': 8},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.7733741,\n",
              "  'index': 4,\n",
              "  'word': 'm',\n",
              "  'start': 9,\n",
              "  'end': 10},\n",
              " {'entity': 'I-PER',\n",
              "  'score': 0.4488581,\n",
              "  'index': 5,\n",
              "  'word': '##od',\n",
              "  'start': 10,\n",
              "  'end': 12},\n",
              " {'entity': 'B-LOC',\n",
              "  'score': 0.99941087,\n",
              "  'index': 27,\n",
              "  'word': 'Delhi',\n",
              "  'start': 96,\n",
              "  'end': 101}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner(\"Narendra modi on the 15th of august 2024 addressed the people  of the country from the red fort,Delhi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiNIprhgFlAQ",
        "outputId": "6587af9b-7eb4-43fc-e7b5-76f83b460cb6"
      },
      "outputs": [],
      "source": [
        "qa = pipeline(\"question-answering\",\n",
        "              model=\"distilbert/distilbert-base-cased-distilled-squad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mZXeJn2GnoV",
        "outputId": "cfd42eb4-87d0-4315-e69f-e99c599d1848"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.0393952876329422,\n",
              " 'start': 49,\n",
              " 'end': 100,\n",
              " 'answer': 'a Serbian-American engineer, futurist, and inventor'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ctx=\"Nikola Tesla (10 July 1856 – 7 January 1943) was a Serbian-American engineer, \\\n",
        "futurist, and inventor. He is known for his contributions to the design of the modern alternating current (AC) electricity supply system.\\\n",
        "Born and raised in the Austrian Empire, Tesla first studied engineering and physics in the 1870s without receiving a degree. He then gained \\\n",
        "practical experience in the early 1880s working in telephony and at Continental Edison in the new electric power industry. In 1884 he immigrated\\\n",
        " to the United States, where he became a naturalized citizen. He worked for a short time at the Edison Machine Works in New York City before he \\\n",
        " struck out on his own. With the help of partners to finance and market his ideas, Tesla set up laboratories and companies in New York to develop a\\\n",
        "  range of electrical and mechanical devices. His AC induction motor and related polyphase AC patents, licensed by Westinghouse Electric in 1888, earned\\\n",
        "   him a considerable amount of money and became the cornerstone of the polyphase system which that company eventually marketed.\\\n",
        "Attempting to develop inventions he could patent and market, Tesla conducted a range of experiments with mechanical oscillators/generators,\\\n",
        " electrical discharge tubes, and early X-ray imaging. He also built a wirelessly controlled boat, one of the first ever exhibited. Tesla became \\\n",
        " well known as an inventor and demonstrated his achievements to celebrities and wealthy patrons at his lab, and was noted for his showmanship at public \\\n",
        " lectures. Throughout the 1890s, Tesla pursued his ideas for wireless lighting and worldwide wireless electric power distribution in his high-voltage, high-frequency\\\n",
        "  power experiments in New York and Colorado Springs. In 1893, he made pronouncements on the possibility of wireless communication with his devices. Tesla tried to put\\\n",
        "   these ideas to practical use in his unfinished Wardenclyffe Tower project, an intercontinental wireless communication and power transmitter, but ran out of funding before \\\n",
        "   he could complete it.\"\n",
        "\n",
        "q=\"who was Nikola Tesla\"\n",
        "\n",
        "qa(context=ctx,question=q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmclUuaBGtV0",
        "outputId": "8a9f536b-6816-4789-ea1d-ca0a3f673256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.10.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.3->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ob1vy3qIJdaZ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "# Define the function that performs question answering\n",
        "def answer_question(question,context ):\n",
        "    # The pipeline takes a question and context, and returns an answer\n",
        "    return qa(question=question, context=context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h8XDW2ZjK3PM"
      },
      "outputs": [],
      "source": [
        "# Create a Gradio interface\n",
        "interface = gr.Interface(fn=answer_question,\n",
        "                         inputs=[gr.Textbox(label=\"Enter Context\"),\n",
        "                                 gr.Textbox(label=\"Enter Question\")],\n",
        "                         outputs=\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UlZ-lqQeMBFD"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pkfile=open(\"qa.pkl\",\"wb\")\n",
        "pickle.dump(qa,pkfile)\n",
        "pkfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dDO5DyXxMnJj"
      },
      "outputs": [],
      "source": [
        "def answer(question,file):\n",
        "  infile=open('/content/qa.pkl','rb')\n",
        "  objload=pickle.load(infile)\n",
        "  with open(file,'r') as readfile:\n",
        "    ctx=readfile.read()\n",
        "  infile.close()\n",
        "  resp=objload(context=ctx,question=question)\n",
        "  return resp['answer']\n",
        "\n",
        "demo=gr.Interface(\n",
        "     fn=answer,\n",
        "     inputs=[\"text\",gr.File(label=\"Information File\")],\n",
        "     outputs=[\"text\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "j3q9-TsKOihk",
        "outputId": "e03b6582-6621-4629-d766-fa619815ffa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://96be4a155df4df5280.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://96be4a155df4df5280.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4cxXAo1IOmhC"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11f8f1a1dc2e4f38b0d6ff60c77b5d0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\anaconda3\\envs\\dung\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dbda.STUDENTSDC\\.cache\\huggingface\\hub\\models--gsarti--it5-small-news-summarization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e961a4eb8f94aa6bb46960c9fdbf879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5df17a2bfa4d4483a9a6889cc0954c8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b39bd3bf89b4f5498486ac50a906bf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8722d1f136a46079a8a0c1253f065c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "324f3c572f1e400eb41297cb5b25c7ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'nikola tesla, 10 july 1856 – 7 january 1943, was a serbian-american engineer, futurist, and inventor. he is known for his contributions to the design of the modern alternating current (ac) electric power industry.'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"gsarti/it5-small-news-summarization\")\n",
        "summarizer(ctx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'nikola tesla, 10 july 1856 – 7 january 1943, was a serbian-american engineer, futurist, and inventor. he is known for his contributions to the design of the modern alternating current (ac) electric power industry.'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'train.csv', 'validation': 'validation.csv', 'test': 'test.csv'}\n",
        "df = pd.read_csv(\"hf://datasets/neil-code/dialogsum-test/\" + splits[\"test\"])\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"gsarti/it5-small-news-summarization\")\n",
        "summarizer(ctx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0_1</td>\n",
              "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>communication method</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_0_2</td>\n",
              "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>company policy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_0_3</td>\n",
              "      <td>#Person1#: Ms. Dawson, I need you to take a di...</td>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>dictation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_1_1</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>public transportation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_1_2</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>transportation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>test_164_3</td>\n",
              "      <td>#Person1#: Does it look like a good fit?\\n#Per...</td>\n",
              "      <td>#Person1# purchases some clothes by credit car...</td>\n",
              "      <td>purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>test_165_1</td>\n",
              "      <td>#Person1#: Mr. Blake? Mr. Foster's on the phon...</td>\n",
              "      <td>Mr. Blake explains the training manuals cannot...</td>\n",
              "      <td>office phone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>test_165_2</td>\n",
              "      <td>#Person1#: Mr. Blake? Mr. Foster's on the phon...</td>\n",
              "      <td>#Person1# is transferring the message between ...</td>\n",
              "      <td>training manuals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>test_165_3</td>\n",
              "      <td>#Person1#: Mr. Blake? Mr. Foster's on the phon...</td>\n",
              "      <td>Mr. Foster wants the training manuals to be se...</td>\n",
              "      <td>send training manuals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>test_166_1</td>\n",
              "      <td>#Person1#: Are you going anywhere for your vac...</td>\n",
              "      <td>#Person2# tells David about #Person2#'s planne...</td>\n",
              "      <td>vacation plan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>499 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                           dialogue  \\\n",
              "0      test_0_1  #Person1#: Ms. Dawson, I need you to take a di...   \n",
              "1      test_0_2  #Person1#: Ms. Dawson, I need you to take a di...   \n",
              "2      test_0_3  #Person1#: Ms. Dawson, I need you to take a di...   \n",
              "3      test_1_1  #Person1#: You're finally here! What took so l...   \n",
              "4      test_1_2  #Person1#: You're finally here! What took so l...   \n",
              "..          ...                                                ...   \n",
              "494  test_164_3  #Person1#: Does it look like a good fit?\\n#Per...   \n",
              "495  test_165_1  #Person1#: Mr. Blake? Mr. Foster's on the phon...   \n",
              "496  test_165_2  #Person1#: Mr. Blake? Mr. Foster's on the phon...   \n",
              "497  test_165_3  #Person1#: Mr. Blake? Mr. Foster's on the phon...   \n",
              "498  test_166_1  #Person1#: Are you going anywhere for your vac...   \n",
              "\n",
              "                                               summary                  topic  \n",
              "0    Ms. Dawson helps #Person1# to write a memo to ...   communication method  \n",
              "1    In order to prevent employees from wasting tim...         company policy  \n",
              "2    Ms. Dawson takes a dictation for #Person1# abo...              dictation  \n",
              "3    #Person2# arrives late because of traffic jam....  public transportation  \n",
              "4    #Person2# decides to follow #Person1#'s sugges...         transportation  \n",
              "..                                                 ...                    ...  \n",
              "494  #Person1# purchases some clothes by credit car...               purchase  \n",
              "495  Mr. Blake explains the training manuals cannot...           office phone  \n",
              "496  #Person1# is transferring the message between ...       training manuals  \n",
              "497  Mr. Foster wants the training manuals to be se...  send training manuals  \n",
              "498  #Person2# tells David about #Person2#'s planne...          vacation plan  \n",
              "\n",
              "[499 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6003]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "#Compute embedding for both lists\n",
        "embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
        "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
        "\n",
        "util.pytorch_cos_sim(embedding_1, embedding_2)\n",
        "## tensor([[0.6003]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 512, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n"
          ]
        }
      ],
      "source": [
        "tensor1 = summarizer(df['summary'][0], return_tensors=True, max_length=512, truncation=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([59])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor1[0]['summary_token_ids'].shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dung",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
